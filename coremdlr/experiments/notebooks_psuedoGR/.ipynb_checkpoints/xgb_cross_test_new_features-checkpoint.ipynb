{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from collections import deque\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from corebreakout.facies.viz import model_plots, CorePlotter\n",
    "from corebreakout.facies.models import LambdaModel, FeaturePredictor\n",
    "from corebreakout.facies.datasets import FaciesDataset\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `LambdaModel` feature reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_function(x):\n",
    "    feats = []\n",
    "    \n",
    "    feats.append(np.mean(x, axis=1))\n",
    "    feats.append(np.median(x, axis=1))\n",
    "    feats.append(np.var(x, axis=1))\n",
    "    \n",
    "    x_feats = np.concatenate(feats, axis=-1)\n",
    "    \n",
    "    return x_feats\n",
    "\n",
    "\n",
    "feat_model_args = {\n",
    "    # NOTE: key needs to be feature name AND feature must be specified in model_args\n",
    "    'pseudoGR': {\n",
    "        'model' : 'LambdaModel',\n",
    "        'model_args' : {\n",
    "            'feature' : 'pseudoGR',\n",
    "            'lambda_fn' : reduce_function\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `FeaturePredictor` search space definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hyperopt\n",
    "from hyperopt import hp\n",
    "from hyperopt.pyll.base import scope\n",
    "from sklearn.metrics import f1_score, log_loss\n",
    "from sklearn.utils.class_weight import compute_sample_weight\n",
    "\n",
    "\n",
    "XGB_SEARCH_SPACE = {\n",
    "    'model_type' : 'XGB',\n",
    "    'max_depth' : scope.int(hp.quniform('max_depth', 3, 10, 1)),\n",
    "    'learning_rate' : hp.uniform('learning_rate', 0.01, 0.2),\n",
    "    'n_estimators' : scope.int(hp.quniform('n_estimators', 10, 1000, 1)),\n",
    "    'objective' : 'multi:softprob',\n",
    "    'n_jobs' : 2,\n",
    "    'gamma' : hp.uniform('gamma', 0, 0.5),\n",
    "    'subsample' : hp.uniform('subsample', 0.3, 1),\n",
    "    'colsample_bytree' : hp.uniform('colsample_bytree', 0.3, 1.0),\n",
    "    'colsample_bylevel' : 1,\n",
    "    'reg_alpha' : 0,                                    # L1 penalty\n",
    "    'reg_lambda' : hp.uniform('reg_lambda', 0.1, 10),   # L2 penalty\n",
    "    'tree_method' : 'gpu_exact',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_xgb_model(fdset, model_config):\n",
    "    \n",
    "    xgb_predictor = FeaturePredictor(fdset, \n",
    "                                     model_args=model_config, \n",
    "                                     feature_model_args=feat_model_args)\n",
    "    \n",
    "    test_acc = xgb_predictor.fit(fdset, verbose=False)\n",
    "    \n",
    "    y_proba = xgb_predictor.predict_proba(fdset.X_test)\n",
    "    y_pred = np.argmax(y_proba, axis=-1)\n",
    "    \n",
    "    print('F1 score:', f1_score(fdset.y_test, y_pred, average='macro'))\n",
    "    \n",
    "    return log_loss(fdset.y_test, y_proba) #, sample_weight=sample_weights)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Well:  205-21b-3  from  /home/administrator/Dropbox/core_data/facies/train_data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/administrator/code/python/corebreakout/corebreakout/facies/datasets/utils.py:86: RuntimeWarning: Mean of empty slice\n",
      "  output_features.append(np.nanmean(img, axis=1))\n",
      "/home/administrator/code/python/corebreakout/corebreakout/facies/datasets/utils.py:90: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  output_features.append(np.nanvar(img, axis=1))\n",
      "/home/administrator/anaconda3/envs/core-dev/lib/python3.6/site-packages/numpy/lib/nanfunctions.py:1283: RuntimeWarning: All-NaN slice encountered\n",
      "  overwrite_input, interpolation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted pGR features:  ['Umean', 'Rmean', 'Gmean', 'Bmean', 'Uvar', 'Rvar', 'Gvar', 'Bvar', 'Up10', 'Rp10', 'Gp10', 'Bp10', 'Up90', 'Rp90', 'Gp90', 'Bp90']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Header section Parameter regexp=~P was not found.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding NaN log:  SP\n",
      "Adding NaN log:  DTS\n",
      "Feature shapes:  [('depth', (3842,)), ('top', (3842,)), ('base', (3842,)), ('pseudoGR', (3842, 32, 16)), ('logs', (3842, 11))]\n",
      "Loading Well:  204-20-6a  from  /home/administrator/Dropbox/core_data/facies/train_data\n",
      "Extracted pGR features:  ['Umean', 'Rmean', 'Gmean', 'Bmean', 'Uvar', 'Rvar', 'Gvar', 'Bvar', 'Up10', 'Rp10', 'Gp10', 'Bp10', 'Up90', 'Rp90', 'Gp90', 'Bp90']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Header section Parameter regexp=~P was not found.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding NaN log:  SP\n",
      "Adding NaN log:  DTS1\n",
      "Adding NaN log:  DTS2\n",
      "Feature shapes:  [('depth', (3873,)), ('top', (3873,)), ('base', (3873,)), ('pseudoGR', (3873, 32, 16)), ('logs', (3873, 11))]\n",
      "Loading Well:  204-20-1Z  from  /home/administrator/Dropbox/core_data/facies/train_data\n",
      "Extracted pGR features:  ['Umean', 'Rmean', 'Gmean', 'Bmean', 'Uvar', 'Rvar', 'Gvar', 'Bvar', 'Up10', 'Rp10', 'Gp10', 'Bp10', 'Up90', 'Rp90', 'Gp90', 'Bp90']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Header section Parameter regexp=~P was not found.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding NaN log:  SP\n",
      "Adding NaN log:  DTS1\n",
      "Adding NaN log:  DTS2\n",
      "Feature shapes:  [('depth', (1917,)), ('top', (1917,)), ('base', (1917,)), ('pseudoGR', (1917, 32, 16)), ('logs', (1917, 11))]\n",
      "Loading Well:  204-24a-6  from  /home/administrator/Dropbox/core_data/facies/train_data\n",
      "Extracted pGR features:  ['Umean', 'Rmean', 'Gmean', 'Bmean', 'Uvar', 'Rvar', 'Gvar', 'Bvar', 'Up10', 'Rp10', 'Gp10', 'Bp10', 'Up90', 'Rp90', 'Gp90', 'Bp90']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Header section Parameter regexp=~P was not found.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding NaN log:  SP\n",
      "Adding NaN log:  DTS1\n",
      "Adding NaN log:  DTS2\n",
      "Feature shapes:  [('depth', (13006,)), ('top', (13006,)), ('base', (13006,)), ('pseudoGR', (13006, 32, 16)), ('logs', (13006, 11))]\n",
      "Loading Well:  204-19-6  from  /home/administrator/Dropbox/core_data/facies/train_data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/administrator/code/python/corebreakout/corebreakout/facies/datasets/utils.py:86: RuntimeWarning: Mean of empty slice\n",
      "  output_features.append(np.nanmean(img, axis=1))\n",
      "/home/administrator/code/python/corebreakout/corebreakout/facies/datasets/utils.py:90: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  output_features.append(np.nanvar(img, axis=1))\n",
      "/home/administrator/anaconda3/envs/core-dev/lib/python3.6/site-packages/numpy/lib/nanfunctions.py:1283: RuntimeWarning: All-NaN slice encountered\n",
      "  overwrite_input, interpolation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted pGR features:  ['Umean', 'Rmean', 'Gmean', 'Bmean', 'Uvar', 'Rvar', 'Gvar', 'Bvar', 'Up10', 'Rp10', 'Gp10', 'Bp10', 'Up90', 'Rp90', 'Gp90', 'Bp90']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Header section Parameter regexp=~P was not found.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding NaN log:  DTS\n",
      "Feature shapes:  [('depth', (1884,)), ('top', (1884,)), ('base', (1884,)), ('pseudoGR', (1884, 32, 16)), ('logs', (1884, 11))]\n",
      "Training model for feature:  pseudoGR\n",
      "F1 score: 0.4746510133330064\n",
      "Training model for feature:  pseudoGR\n",
      "F1 score: 0.4827397957571463\n",
      "Training model for feature:  pseudoGR\n",
      "F1 score: 0.4761492895077247\n",
      "Training model for feature:  pseudoGR\n",
      "F1 score: 0.465536847099366\n",
      "Training model for feature:  pseudoGR\n",
      "F1 score: 0.4501957507409934\n",
      "Training model for feature:  pseudoGR\n",
      "F1 score: 0.4749868647341937\n",
      "Training model for feature:  pseudoGR\n",
      "F1 score: 0.47716067828417374\n",
      "Training model for feature:  pseudoGR\n",
      "F1 score: 0.4812483170329912\n",
      "Training model for feature:  pseudoGR\n",
      "F1 score: 0.4819036056906361\n",
      "Training model for feature:  pseudoGR\n",
      "F1 score: 0.430465874984593\n",
      "Training model for feature:  pseudoGR\n",
      "F1 score: 0.46170214175243973\n",
      "Training model for feature:  pseudoGR\n",
      "F1 score: 0.43867350521154824\n",
      "Training model for feature:  pseudoGR\n",
      "F1 score: 0.4830642116766271\n",
      "Training model for feature:  pseudoGR\n",
      "F1 score: 0.4811393885003864\n",
      "Training model for feature:  pseudoGR\n",
      "F1 score: 0.48348436051881116\n",
      "Training model for feature:  pseudoGR\n",
      "F1 score: 0.45868374871215745\n",
      "Training model for feature:  pseudoGR\n",
      "F1 score: 0.48181370723152506\n",
      "Training model for feature:  pseudoGR\n",
      "F1 score: 0.4787486729678999\n",
      "Training model for feature:  pseudoGR\n",
      "F1 score: 0.47402519077312777\n",
      "Training model for feature:  pseudoGR\n",
      "F1 score: 0.4886003164944947\n",
      "Training model for feature:  pseudoGR\n",
      "F1 score: 0.46246177771048835\n",
      "Training model for feature:  pseudoGR\n",
      "F1 score: 0.49045015051495516\n",
      "Training model for feature:  pseudoGR\n",
      "F1 score: 0.4764971009420514\n",
      "Training model for feature:  pseudoGR\n",
      "F1 score: 0.4782385681788791\n",
      "Training model for feature:  pseudoGR\n"
     ]
    }
   ],
   "source": [
    "well_names = [\"205-21b-3\", \"204-20-6a\",\"204-20-1Z\", \"204-24a-6\", \"204-19-6\"]\n",
    "names_deq = deque(well_names)\n",
    "\n",
    "results = {}\n",
    "\n",
    "for i in range(len(names_deq)):\n",
    "    \n",
    "    # Set up dataset, rotate well_names\n",
    "    fdset = FaciesDataset(list(names_deq)[:-1], test_wells=[names_deq[-1]],\n",
    "                        features=[\"pseudoGR\", \"logs\"],\n",
    "                        pseudoGR_args={'features': ['mean', 'var', 'p10', 'p90'], \n",
    "                                                    'per_channel' : True},\n",
    "                        label_resolution=32)\n",
    "    \n",
    "    names_deq.rotate()\n",
    "    \n",
    "    fdset.load_or_generate_data()\n",
    "    \n",
    "    best_params = hyperopt.fmin(\n",
    "        fn=lambda x: train_xgb_model(fdset, x),\n",
    "        space=XGB_SEARCH_SPACE,\n",
    "        algo=hyperopt.rand.suggest,\n",
    "        max_evals=25\n",
    "    )\n",
    "    \n",
    "    params = {\n",
    "        **XGB_SEARCH_SPACE, \n",
    "        **best_params, \n",
    "        **{'max_depth': int(best_params['max_depth']), \n",
    "           'n_estimators': int(best_params['n_estimators'])}\n",
    "    }\n",
    "\n",
    "    xgb_predictor = FeaturePredictor(fdset, model_args=params, feature_model_args=feat_model_args)\n",
    "    \n",
    "    xgb_predictor.fit(fdset, verbose=True)\n",
    "    \n",
    "    # Feature importances\n",
    "    raw_feat_names = fdset.wells[0].pGR_feat_names\n",
    "    feat_names = [f+'_mean' for f in raw_feat_names] + \\\n",
    "                 [f+'_median' for f in raw_feat_names] + \\\n",
    "                 [f+'_var' for f in raw_feat_names]\n",
    "            \n",
    "    imps = list(zip(feat_names, xgb_predictor.model.feature_importances_))\n",
    "    imps.sort(key = lambda p: p[1])\n",
    "    print('\\nFeature Importances:')\n",
    "    [print(pair) for pair in imps[::-1]]\n",
    "    \n",
    "    # Get test results\n",
    "    test_well = fdset.test_well_names[0]\n",
    "    \n",
    "    results[test_well] = xgb_model.preds_dataframe(test_well, logs=['GR', 'RDEP', 'PEF', 'SP'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dfs = []\n",
    "for well_name, results_df in results.items():\n",
    "    results_df['well_name'] = well_name\n",
    "    dfs.append(results_df)\n",
    "    \n",
    "df = pd.concat(dfs, ignore_index=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('cross_test_xgb.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "axes = df.regression.hist(by=df.y_true, figsize=(15,15), alpha=0.4)\n",
    "print(axes)\n",
    "\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    df.regression[df.y_pred==i].hist(ax=ax, color='blue', alpha=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "axes = df.y_true.hist(by=df.well_name, figsize=(15,15), alpha=0.4)\n",
    "\n",
    "well_names = [\"204-19-6\", \"204-20-1Z\", \"204-20-6a\", \"204-24a-6\", \"205-21b-3\"]\n",
    "\n",
    "for i, (ax, name) in enumerate(zip(axes.flat, well_names)):\n",
    "    print(name)\n",
    "    df.y_pred[df.well_name==name].hist(ax=ax, color='blue', alpha=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
