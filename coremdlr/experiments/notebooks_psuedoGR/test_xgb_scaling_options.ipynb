{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing XGB on Psuedo Gamma datasets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from coremdlr.datasets import WellLoader, FaciesDataset\n",
    "from coremdlr.models import FeaturePredictor, LambdaModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare scaling methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Well:  205-21b-3  from  /home/administrator/Dropbox/core_data/facies/train_data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/administrator/code/python/coremdlr/coremdlr/facies/datasets/utils.py:72: RuntimeWarning: Mean of empty slice\n",
      "  output_features.append(np.nanmean(img, axis=1))\n",
      "/home/administrator/code/python/coremdlr/coremdlr/facies/datasets/utils.py:76: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  output_features.append(np.nanvar(img, axis=1))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted pGR features:  ['Umean', 'Rmean', 'Gmean', 'Bmean', 'Uvar', 'Rvar', 'Gvar', 'Bvar']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Header section Parameter regexp=~P was not found.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding NaN log:  SP\n",
      "Adding NaN log:  DTS\n",
      "Feature shapes:  [('depth', (3842,)), ('top', (3842,)), ('base', (3842,)), ('pseudoGR', (3842, 32, 8)), ('logs', (3842, 11))]\n",
      "Loading Well:  204-24a-6  from  /home/administrator/Dropbox/core_data/facies/train_data\n",
      "Extracted pGR features:  ['Umean', 'Rmean', 'Gmean', 'Bmean', 'Uvar', 'Rvar', 'Gvar', 'Bvar']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Header section Parameter regexp=~P was not found.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding NaN log:  SP\n",
      "Adding NaN log:  DTS1\n",
      "Adding NaN log:  DTS2\n",
      "Feature shapes:  [('depth', (13006,)), ('top', (13006,)), ('base', (13006,)), ('pseudoGR', (13006, 32, 8)), ('logs', (13006, 11))]\n",
      "Loading Well:  204-20-6a  from  /home/administrator/Dropbox/core_data/facies/train_data\n",
      "Extracted pGR features:  ['Umean', 'Rmean', 'Gmean', 'Bmean', 'Uvar', 'Rvar', 'Gvar', 'Bvar']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Header section Parameter regexp=~P was not found.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding NaN log:  SP\n",
      "Adding NaN log:  DTS1\n",
      "Adding NaN log:  DTS2\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "b'os' is not in list",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-4bcdd6a7560b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m                     label_resolution=32)\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mfdset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_or_generate_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/code/python/coremdlr/coremdlr/facies/datasets/facies_dataset.py\u001b[0m in \u001b[0;36mload_or_generate_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0mDefine\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0my\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \"\"\"\n\u001b[0;32m--> 119\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwells\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_shift\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwells\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwells\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollapse_missing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/python/coremdlr/coremdlr/facies/datasets/facies_dataset.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0mDefine\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0my\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \"\"\"\n\u001b[0;32m--> 119\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwells\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_shift\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwells\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwells\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollapse_missing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/python/coremdlr/coremdlr/facies/datasets/well_loader.py\u001b[0m in \u001b[0;36mload_data\u001b[0;34m(self, label_names, aggregate, random_shift)\u001b[0m\n\u001b[1;32m    176\u001b[0m                                   kind=self.logs_args['interp_kind'], bounds_error=True)\n\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0maggregate\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/python/coremdlr/coremdlr/facies/datasets/well_loader.py\u001b[0m in \u001b[0;36m_load_labels\u001b[0;34m(self, label_names)\u001b[0m\n\u001b[1;32m    192\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m             \u001b[0mrow_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 194\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrow_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvectorize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlabel_names\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrow_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatasets_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownsample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrow_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownsample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/core-dev/lib/python3.6/site-packages/numpy/lib/function_base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1970\u001b[0m             \u001b[0mvargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m_n\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_n\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1971\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1972\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_vectorize_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1973\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1974\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_ufunc_and_otypes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/core-dev/lib/python3.6/site-packages/numpy/lib/function_base.py\u001b[0m in \u001b[0;36m_vectorize_call\u001b[0;34m(self, func, args)\u001b[0m\n\u001b[1;32m   2046\u001b[0m                       for a in args]\n\u001b[1;32m   2047\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2048\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mufunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2049\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2050\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mufunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnout\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/python/coremdlr/coremdlr/facies/datasets/well_loader.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(l)\u001b[0m\n\u001b[1;32m    192\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m             \u001b[0mrow_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 194\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrow_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvectorize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlabel_names\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrow_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatasets_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownsample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrow_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownsample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: b'os' is not in list"
     ]
    }
   ],
   "source": [
    "fdset = FaciesDataset([\"205-21b-3\", \"204-24a-6\", \"204-20-6a\", \"204-20-1Z\"],\n",
    "                    test_wells=[\"204-19-6\"],\n",
    "                    features=[\"pseudoGR\", \"logs\"],\n",
    "                    pseudoGR_args={'scale_mode': 'robust'}, # can change\n",
    "                    label_resolution=32)\n",
    "\n",
    "fdset.load_or_generate_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading well with dummy labels. DO NOT TRAIN ON THIS WELL!\n",
      "Loading well with dummy labels. DO NOT TRAIN ON THIS WELL!\n",
      "Loading well with dummy labels. DO NOT TRAIN ON THIS WELL!\n",
      "Loading well with dummy labels. DO NOT TRAIN ON THIS WELL!\n",
      "Loading Well:  205-21b-3  from  /home/administrator/Dropbox/core_data/facies/train_data\n",
      "Loading well with dummy labels. DO NOT TRAIN ON THIS WELL!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/administrator/code/python/coremdlr/coremdlr/facies/datasets/utils.py:72: RuntimeWarning: Mean of empty slice\n",
      "  output_features.append(np.nanmean(img, axis=1))\n",
      "/home/administrator/code/python/coremdlr/coremdlr/facies/datasets/utils.py:76: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  output_features.append(np.nanvar(img, axis=1))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted pGR features:  ['Umean', 'Rmean', 'Gmean', 'Bmean', 'Uvar', 'Rvar', 'Gvar', 'Bvar']\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-e43545fc7721>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m                     label_resolution=32)\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mfdset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_or_generate_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mpGR\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfdset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pseudoGR'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/python/coremdlr/coremdlr/facies/datasets/facies_dataset.py\u001b[0m in \u001b[0;36mload_or_generate_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0mDefine\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0my\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \"\"\"\n\u001b[0;32m--> 119\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwells\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_shift\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwells\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwells\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollapse_missing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/python/coremdlr/coremdlr/facies/datasets/facies_dataset.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0mDefine\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0my\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \"\"\"\n\u001b[0;32m--> 119\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwells\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_shift\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwells\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwells\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollapse_missing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/python/coremdlr/coremdlr/facies/datasets/well_loader.py\u001b[0m in \u001b[0;36mload_data\u001b[0;34m(self, label_names, aggregate, random_shift)\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0maggregate\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_aggregate_instances\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_shift\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrandom_shift\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/python/coremdlr/coremdlr/facies/datasets/well_loader.py\u001b[0m in \u001b[0;36m_aggregate_instances\u001b[0;34m(self, random_shift)\u001b[0m\n\u001b[1;32m    219\u001b[0m         \u001b[0;31m# split labels + data into 'patches'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel_tops\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_bottoms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_y\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrow_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m             \u001b[0mdepth\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmedian\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_depth\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tops\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_depth\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence."
     ]
    }
   ],
   "source": [
    "for scale_mode in [None, 'minmax', 'standard', 'robust', 'power']:\n",
    "    \n",
    "    fdset = FaciesDataset([\"205-21b-3\", \"204-20-6a\", \"204-19-6\", \"204-24a-6\"],\n",
    "                    test_wells=[],\n",
    "                    features=[\"pseudoGR\"],\n",
    "                    pseudoGR_args={'scale_mode': scale_mode},\n",
    "                    label_resolution=32)\n",
    "    \n",
    "    fdset.load_or_generate_data()\n",
    "    \n",
    "    pGR = fdset.X_train['pseudoGR'].flatten()\n",
    "    min_y, max_y = pGR.min(), pGR.max()\n",
    "    \n",
    "    plt.figure(figsize=(20,5))\n",
    "    plt.title(scale_mode, size=24)\n",
    "    plt.plot(np.arange(pGR.size), pGR)\n",
    "    \n",
    "    for idx in fdset.X_train['boundary_idxs']:\n",
    "        plt.plot([idx*32, idx*32], [min_y,max_y], color='red')\n",
    "        \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import warnings\n",
    "\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'FaciesDataset' object has no attribute 'y_test'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-5fc6c257a58f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# for balanced log_loss computation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0msample_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_sample_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'balanced'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfdset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# feat_names = ['mean', 'median', 'hmean', 'gmean', 'var', 'IF_0', 'IF_1', 'Chi2', 'p-val']\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'FaciesDataset' object has no attribute 'y_test'"
     ]
    }
   ],
   "source": [
    "import hyperopt\n",
    "from hyperopt import hp\n",
    "from hyperopt.pyll.base import scope\n",
    "from sklearn.metrics import f1_score, log_loss\n",
    "from sklearn.utils.class_weight import compute_sample_weight\n",
    "\n",
    "from scipy.stats import mstats\n",
    "\n",
    "\n",
    "# for balanced log_loss computation\n",
    "sample_weights = compute_sample_weight('balanced', fdset.y_test) \n",
    "\n",
    "# feat_names = ['mean', 'median', 'hmean', 'gmean', 'var', 'IF_0', 'IF_1', 'Chi2', 'p-val']\n",
    "feat_names = ['mean', 'median', 'gmean', 'var', 'IF_0', 'IF_1', 'm3', 'm2', 'm1', 'b']\n",
    "\n",
    "def polyfit_coeffs(x):\n",
    "    p = np.ma.polyfit(np.arange(x.shape[1]), x.T, 3)\n",
    "    return p.T\n",
    "\n",
    "\n",
    "def reduce_function(x):\n",
    "    feats = []\n",
    "    x = np.ma.masked_invalid(x)\n",
    "    feats.append(np.mean(x, axis=-1))\n",
    "    feats.append(np.median(x, axis=-1))\n",
    "    #feats.append(mstats.hmean(x-x.min(), axis=-1))\n",
    "    feats.append(mstats.gmean(x, axis=-1))\n",
    "    feats.append(np.var(x, axis=-1))\n",
    "    \n",
    "    # feats.append(sp.signal.qspline1d(x))\n",
    "    ideal_fourths = mstats.idealfourths(x, axis=-1)\n",
    "    feats.append(ideal_fourths[:, 0])\n",
    "    feats.append(ideal_fourths[:, 1])\n",
    "    \n",
    "    coeffs = polyfit_coeffs(x)\n",
    "    for i in range(4):\n",
    "        feats.append(coeffs[:,i])\n",
    "    \n",
    "    #normal_test = mstats.normaltest(x, axis=1)\n",
    "    #feats.append(normal_test[0])\n",
    "    #feats.append(normal_test[1])\n",
    "    # kur_test = mstats.kurtosistest(x, axis =-1)\n",
    "    # feats.append(kurtosistest[:, 0])\n",
    "    # feats.append(kurtosistest[:, 1])\n",
    "    \n",
    "    x_feats = np.array(feats).T\n",
    "    return x_feats\n",
    "\n",
    "\n",
    "feat_model_args = {\n",
    "    # NOTE: key needs to be feature name AND feature must be specified in model_args\n",
    "    'pseudoGR': {\n",
    "        'model' : 'LambdaModel',\n",
    "        'model_args' : {\n",
    "            'feature' : 'pseudoGR',\n",
    "            'lambda_fn' : reduce_function\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "XGB_SEARCH_SPACE = {\n",
    "    'model_type' : 'XGB',\n",
    "    'max_depth' : scope.int(hp.quniform('max_depth', 3, 10, 1)),\n",
    "    'learning_rate' : hp.uniform('learning_rate', 0.01, 0.2),\n",
    "    'n_estimators' : scope.int(hp.quniform('n_estimators', 10, 1000, 1)),\n",
    "    'objective' : 'multi:softprob',\n",
    "    'n_jobs' : 2,\n",
    "    'gamma' : hp.uniform('gamma', 0, 0.5),\n",
    "    'subsample' : hp.uniform('subsample', 0.3, 1),\n",
    "    'colsample_bytree' : hp.uniform('colsample_bytree', 0.3, 1.0),\n",
    "    'colsample_bylevel' : 1,\n",
    "    'reg_alpha' : 0,                                    # L1 penalty\n",
    "    'reg_lambda' : hp.uniform('reg_lambda', 0.1, 10),   # L2 penalty\n",
    "    'tree_method' : 'gpu_exact',\n",
    "}\n",
    "\n",
    "def train_xgb_model(model_config):\n",
    "    xgb_predictor = FeaturePredictor(fdset, \n",
    "                                     model_args=model_config, \n",
    "                                     feature_model_args=feat_model_args)\n",
    "    test_acc = xgb_predictor.fit(fdset, verbose=False)\n",
    "    y_pred = xgb_predictor.predict(fdset.X_test)\n",
    "    print('F1 score:', f1_score(fdset.y_test, y_pred, average='macro'))\n",
    "    return log_loss(fdset.y_test, xgb_predictor.predict_proba(fdset.X_test)) #, sample_weight=sample_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_xgb_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-cb969362d2f7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m best_params = hyperopt.fmin(\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mfn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_xgb_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mspace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mXGB_SEARCH_SPACE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0malgo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhyperopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuggest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mmax_evals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_xgb_model' is not defined"
     ]
    }
   ],
   "source": [
    "best_params = hyperopt.fmin(\n",
    "    fn=train_xgb_model,\n",
    "    space=XGB_SEARCH_SPACE,\n",
    "    algo=hyperopt.rand.suggest,\n",
    "    max_evals=20\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'best_params' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-bca2bedf354b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbest_params\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'best_params' is not defined"
     ]
    }
   ],
   "source": [
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for feature:  pseudoGR\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "           sandstone       0.67      0.83      0.74       934\n",
      "clay-prone sandstone       0.06      0.01      0.01       307\n",
      "      sandy mudstone       0.31      0.34      0.32       285\n",
      "            mudstone       0.52      0.56      0.54       358\n",
      "\n",
      "           micro avg       0.57      0.57      0.57      1884\n",
      "           macro avg       0.39      0.43      0.41      1884\n",
      "        weighted avg       0.49      0.57      0.52      1884\n",
      "\n",
      "Total accuracy Score :  0.5705944798301487\n",
      "Confusion Matrix: \n",
      " [[774   1  81  78]\n",
      " [240   2  41  24]\n",
      " [ 97   9  97  82]\n",
      " [ 40  21  95 202]]\n",
      "('var', 0.23755158)\n",
      "('IF_0', 0.122206144)\n",
      "('IF_1', 0.12049097)\n",
      "('b', 0.106983975)\n",
      "('m1', 0.090368226)\n",
      "('m3', 0.07696843)\n",
      "('median', 0.07503886)\n",
      "('m2', 0.0655518)\n",
      "('mean', 0.057297528)\n",
      "('gmean', 0.04754248)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None, None, None, None, None, None, None, None]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {**XGB_SEARCH_SPACE, \n",
    "          **best_params, \n",
    "          **{'max_depth': int(best_params['max_depth']), 'n_estimators': int(best_params['n_estimators'])}}\n",
    "\n",
    "xgb_predictor = FeaturePredictor(fdset, model_args=params, feature_model_args=feat_model_args)\n",
    "xgb_predictor.fit(fdset, verbose=True)\n",
    "\n",
    "imps = list(zip(feat_names, xgb_predictor.model.feature_importances_))\n",
    "imps.sort(key = lambda p: p[1])\n",
    "[print(pair) for pair in imps[::-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>proba_0</th>\n",
       "      <th>proba_1</th>\n",
       "      <th>proba_2</th>\n",
       "      <th>proba_3</th>\n",
       "      <th>y_pred</th>\n",
       "      <th>y_true</th>\n",
       "      <th>confidence</th>\n",
       "      <th>regression</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.605535</td>\n",
       "      <td>0.077053</td>\n",
       "      <td>0.045951</td>\n",
       "      <td>0.271461</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.605535</td>\n",
       "      <td>0.983338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.380717</td>\n",
       "      <td>0.150265</td>\n",
       "      <td>0.144761</td>\n",
       "      <td>0.324257</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.380717</td>\n",
       "      <td>1.412557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.477954</td>\n",
       "      <td>0.131226</td>\n",
       "      <td>0.251586</td>\n",
       "      <td>0.139233</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.477954</td>\n",
       "      <td>1.052099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.336278</td>\n",
       "      <td>0.146381</td>\n",
       "      <td>0.361847</td>\n",
       "      <td>0.155493</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.361847</td>\n",
       "      <td>1.336556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.499443</td>\n",
       "      <td>0.119775</td>\n",
       "      <td>0.272626</td>\n",
       "      <td>0.108157</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.499443</td>\n",
       "      <td>0.989497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.388417</td>\n",
       "      <td>0.180838</td>\n",
       "      <td>0.285031</td>\n",
       "      <td>0.145714</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.388417</td>\n",
       "      <td>1.188042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.347153</td>\n",
       "      <td>0.172329</td>\n",
       "      <td>0.316651</td>\n",
       "      <td>0.163866</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.347153</td>\n",
       "      <td>1.297231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.350827</td>\n",
       "      <td>0.148594</td>\n",
       "      <td>0.362738</td>\n",
       "      <td>0.137841</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.362738</td>\n",
       "      <td>1.287593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.319974</td>\n",
       "      <td>0.176045</td>\n",
       "      <td>0.357020</td>\n",
       "      <td>0.146962</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.357020</td>\n",
       "      <td>1.330969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.432444</td>\n",
       "      <td>0.166799</td>\n",
       "      <td>0.230379</td>\n",
       "      <td>0.170378</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.432444</td>\n",
       "      <td>1.138692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.472323</td>\n",
       "      <td>0.118969</td>\n",
       "      <td>0.207762</td>\n",
       "      <td>0.200945</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.472323</td>\n",
       "      <td>1.137329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.729920</td>\n",
       "      <td>0.068614</td>\n",
       "      <td>0.029039</td>\n",
       "      <td>0.172427</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.729920</td>\n",
       "      <td>0.643973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.607436</td>\n",
       "      <td>0.088575</td>\n",
       "      <td>0.111937</td>\n",
       "      <td>0.192053</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.607436</td>\n",
       "      <td>0.888606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.657774</td>\n",
       "      <td>0.115337</td>\n",
       "      <td>0.116620</td>\n",
       "      <td>0.110269</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.657774</td>\n",
       "      <td>0.679383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.639450</td>\n",
       "      <td>0.148631</td>\n",
       "      <td>0.118645</td>\n",
       "      <td>0.093275</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.639450</td>\n",
       "      <td>0.665745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.588149</td>\n",
       "      <td>0.156873</td>\n",
       "      <td>0.141329</td>\n",
       "      <td>0.113649</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.588149</td>\n",
       "      <td>0.780477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.642063</td>\n",
       "      <td>0.120757</td>\n",
       "      <td>0.157698</td>\n",
       "      <td>0.079482</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.642063</td>\n",
       "      <td>0.674598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.737879</td>\n",
       "      <td>0.087814</td>\n",
       "      <td>0.115359</td>\n",
       "      <td>0.058948</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.737879</td>\n",
       "      <td>0.495376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.684406</td>\n",
       "      <td>0.097772</td>\n",
       "      <td>0.127541</td>\n",
       "      <td>0.090281</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.684406</td>\n",
       "      <td>0.623696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.691244</td>\n",
       "      <td>0.135606</td>\n",
       "      <td>0.131078</td>\n",
       "      <td>0.042072</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.691244</td>\n",
       "      <td>0.523978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.605265</td>\n",
       "      <td>0.134379</td>\n",
       "      <td>0.206675</td>\n",
       "      <td>0.053681</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.605265</td>\n",
       "      <td>0.708772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.923573</td>\n",
       "      <td>0.039250</td>\n",
       "      <td>0.014314</td>\n",
       "      <td>0.022863</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.923573</td>\n",
       "      <td>0.136467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.829792</td>\n",
       "      <td>0.057373</td>\n",
       "      <td>0.015190</td>\n",
       "      <td>0.097645</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.829792</td>\n",
       "      <td>0.380688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.942767</td>\n",
       "      <td>0.026828</td>\n",
       "      <td>0.007986</td>\n",
       "      <td>0.022419</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.942767</td>\n",
       "      <td>0.110057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.956547</td>\n",
       "      <td>0.019709</td>\n",
       "      <td>0.006390</td>\n",
       "      <td>0.017354</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.956547</td>\n",
       "      <td>0.084551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.922171</td>\n",
       "      <td>0.036993</td>\n",
       "      <td>0.010566</td>\n",
       "      <td>0.030270</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.922171</td>\n",
       "      <td>0.148935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.920370</td>\n",
       "      <td>0.038394</td>\n",
       "      <td>0.010967</td>\n",
       "      <td>0.030270</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.920370</td>\n",
       "      <td>0.151136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.935546</td>\n",
       "      <td>0.029713</td>\n",
       "      <td>0.008573</td>\n",
       "      <td>0.026168</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.935546</td>\n",
       "      <td>0.125364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.939665</td>\n",
       "      <td>0.027868</td>\n",
       "      <td>0.008296</td>\n",
       "      <td>0.024171</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.939665</td>\n",
       "      <td>0.116972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.942216</td>\n",
       "      <td>0.023917</td>\n",
       "      <td>0.007876</td>\n",
       "      <td>0.025990</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.942216</td>\n",
       "      <td>0.117640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1854</th>\n",
       "      <td>0.892545</td>\n",
       "      <td>0.057149</td>\n",
       "      <td>0.023222</td>\n",
       "      <td>0.027085</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.892545</td>\n",
       "      <td>0.184847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1855</th>\n",
       "      <td>0.961319</td>\n",
       "      <td>0.018777</td>\n",
       "      <td>0.006115</td>\n",
       "      <td>0.013789</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.961319</td>\n",
       "      <td>0.072374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1856</th>\n",
       "      <td>0.749548</td>\n",
       "      <td>0.114185</td>\n",
       "      <td>0.019516</td>\n",
       "      <td>0.116750</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.749548</td>\n",
       "      <td>0.503469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1857</th>\n",
       "      <td>0.674184</td>\n",
       "      <td>0.204026</td>\n",
       "      <td>0.032775</td>\n",
       "      <td>0.089015</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.674184</td>\n",
       "      <td>0.536621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1858</th>\n",
       "      <td>0.958773</td>\n",
       "      <td>0.018044</td>\n",
       "      <td>0.006239</td>\n",
       "      <td>0.016944</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.958773</td>\n",
       "      <td>0.081354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1859</th>\n",
       "      <td>0.953622</td>\n",
       "      <td>0.022707</td>\n",
       "      <td>0.006370</td>\n",
       "      <td>0.017301</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.953622</td>\n",
       "      <td>0.087351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1860</th>\n",
       "      <td>0.958606</td>\n",
       "      <td>0.021018</td>\n",
       "      <td>0.006260</td>\n",
       "      <td>0.014116</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.958606</td>\n",
       "      <td>0.075886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1861</th>\n",
       "      <td>0.959270</td>\n",
       "      <td>0.020868</td>\n",
       "      <td>0.006102</td>\n",
       "      <td>0.013760</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.959270</td>\n",
       "      <td>0.074352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1862</th>\n",
       "      <td>0.939205</td>\n",
       "      <td>0.033414</td>\n",
       "      <td>0.012164</td>\n",
       "      <td>0.015216</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.939205</td>\n",
       "      <td>0.103391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1863</th>\n",
       "      <td>0.868050</td>\n",
       "      <td>0.052327</td>\n",
       "      <td>0.054751</td>\n",
       "      <td>0.024872</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.868050</td>\n",
       "      <td>0.236445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1864</th>\n",
       "      <td>0.886798</td>\n",
       "      <td>0.036520</td>\n",
       "      <td>0.056507</td>\n",
       "      <td>0.020174</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.886798</td>\n",
       "      <td>0.210058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1865</th>\n",
       "      <td>0.882143</td>\n",
       "      <td>0.040348</td>\n",
       "      <td>0.049786</td>\n",
       "      <td>0.027722</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.882143</td>\n",
       "      <td>0.223088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1866</th>\n",
       "      <td>0.865635</td>\n",
       "      <td>0.041998</td>\n",
       "      <td>0.057360</td>\n",
       "      <td>0.035007</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.865635</td>\n",
       "      <td>0.261738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867</th>\n",
       "      <td>0.860071</td>\n",
       "      <td>0.045958</td>\n",
       "      <td>0.056441</td>\n",
       "      <td>0.037530</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.860071</td>\n",
       "      <td>0.271430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1868</th>\n",
       "      <td>0.869419</td>\n",
       "      <td>0.041862</td>\n",
       "      <td>0.057165</td>\n",
       "      <td>0.031554</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.869419</td>\n",
       "      <td>0.250854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1869</th>\n",
       "      <td>0.886257</td>\n",
       "      <td>0.036553</td>\n",
       "      <td>0.054973</td>\n",
       "      <td>0.022216</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.886257</td>\n",
       "      <td>0.213148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1870</th>\n",
       "      <td>0.880457</td>\n",
       "      <td>0.040301</td>\n",
       "      <td>0.049728</td>\n",
       "      <td>0.029514</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.880457</td>\n",
       "      <td>0.228300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1871</th>\n",
       "      <td>0.868302</td>\n",
       "      <td>0.044060</td>\n",
       "      <td>0.056153</td>\n",
       "      <td>0.031485</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.868302</td>\n",
       "      <td>0.250821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1872</th>\n",
       "      <td>0.808277</td>\n",
       "      <td>0.072007</td>\n",
       "      <td>0.073849</td>\n",
       "      <td>0.045868</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.808277</td>\n",
       "      <td>0.357307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1873</th>\n",
       "      <td>0.475748</td>\n",
       "      <td>0.156304</td>\n",
       "      <td>0.222501</td>\n",
       "      <td>0.145447</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.475748</td>\n",
       "      <td>1.037648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1874</th>\n",
       "      <td>0.607726</td>\n",
       "      <td>0.134438</td>\n",
       "      <td>0.135215</td>\n",
       "      <td>0.122621</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.607726</td>\n",
       "      <td>0.772732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1875</th>\n",
       "      <td>0.583026</td>\n",
       "      <td>0.137729</td>\n",
       "      <td>0.152405</td>\n",
       "      <td>0.126839</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.583026</td>\n",
       "      <td>0.823057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1876</th>\n",
       "      <td>0.577112</td>\n",
       "      <td>0.126863</td>\n",
       "      <td>0.186181</td>\n",
       "      <td>0.109845</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.577112</td>\n",
       "      <td>0.828758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1877</th>\n",
       "      <td>0.367023</td>\n",
       "      <td>0.150592</td>\n",
       "      <td>0.341523</td>\n",
       "      <td>0.140862</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.367023</td>\n",
       "      <td>1.256224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1878</th>\n",
       "      <td>0.227425</td>\n",
       "      <td>0.159985</td>\n",
       "      <td>0.395985</td>\n",
       "      <td>0.216604</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.395985</td>\n",
       "      <td>1.601767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1879</th>\n",
       "      <td>0.113856</td>\n",
       "      <td>0.113587</td>\n",
       "      <td>0.262781</td>\n",
       "      <td>0.509776</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.509776</td>\n",
       "      <td>2.168476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1880</th>\n",
       "      <td>0.090292</td>\n",
       "      <td>0.092355</td>\n",
       "      <td>0.172258</td>\n",
       "      <td>0.645095</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.645095</td>\n",
       "      <td>2.372156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1881</th>\n",
       "      <td>0.117120</td>\n",
       "      <td>0.123848</td>\n",
       "      <td>0.342103</td>\n",
       "      <td>0.416928</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.416928</td>\n",
       "      <td>2.058840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1882</th>\n",
       "      <td>0.164007</td>\n",
       "      <td>0.146580</td>\n",
       "      <td>0.396678</td>\n",
       "      <td>0.292735</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.396678</td>\n",
       "      <td>1.818140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1883</th>\n",
       "      <td>0.367793</td>\n",
       "      <td>0.140939</td>\n",
       "      <td>0.333788</td>\n",
       "      <td>0.157480</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.367793</td>\n",
       "      <td>1.280956</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1884 rows  8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       proba_0   proba_1   proba_2   proba_3  y_pred  y_true  confidence  \\\n",
       "0     0.605535  0.077053  0.045951  0.271461       0       3    0.605535   \n",
       "1     0.380717  0.150265  0.144761  0.324257       0       3    0.380717   \n",
       "2     0.477954  0.131226  0.251586  0.139233       0       3    0.477954   \n",
       "3     0.336278  0.146381  0.361847  0.155493       2       3    0.361847   \n",
       "4     0.499443  0.119775  0.272626  0.108157       0       3    0.499443   \n",
       "5     0.388417  0.180838  0.285031  0.145714       0       3    0.388417   \n",
       "6     0.347153  0.172329  0.316651  0.163866       0       3    0.347153   \n",
       "7     0.350827  0.148594  0.362738  0.137841       2       3    0.362738   \n",
       "8     0.319974  0.176045  0.357020  0.146962       2       3    0.357020   \n",
       "9     0.432444  0.166799  0.230379  0.170378       0       0    0.432444   \n",
       "10    0.472323  0.118969  0.207762  0.200945       0       0    0.472323   \n",
       "11    0.729920  0.068614  0.029039  0.172427       0       0    0.729920   \n",
       "12    0.607436  0.088575  0.111937  0.192053       0       0    0.607436   \n",
       "13    0.657774  0.115337  0.116620  0.110269       0       0    0.657774   \n",
       "14    0.639450  0.148631  0.118645  0.093275       0       0    0.639450   \n",
       "15    0.588149  0.156873  0.141329  0.113649       0       0    0.588149   \n",
       "16    0.642063  0.120757  0.157698  0.079482       0       0    0.642063   \n",
       "17    0.737879  0.087814  0.115359  0.058948       0       0    0.737879   \n",
       "18    0.684406  0.097772  0.127541  0.090281       0       0    0.684406   \n",
       "19    0.691244  0.135606  0.131078  0.042072       0       0    0.691244   \n",
       "20    0.605265  0.134379  0.206675  0.053681       0       0    0.605265   \n",
       "21    0.923573  0.039250  0.014314  0.022863       0       0    0.923573   \n",
       "22    0.829792  0.057373  0.015190  0.097645       0       0    0.829792   \n",
       "23    0.942767  0.026828  0.007986  0.022419       0       0    0.942767   \n",
       "24    0.956547  0.019709  0.006390  0.017354       0       0    0.956547   \n",
       "25    0.922171  0.036993  0.010566  0.030270       0       0    0.922171   \n",
       "26    0.920370  0.038394  0.010967  0.030270       0       0    0.920370   \n",
       "27    0.935546  0.029713  0.008573  0.026168       0       0    0.935546   \n",
       "28    0.939665  0.027868  0.008296  0.024171       0       0    0.939665   \n",
       "29    0.942216  0.023917  0.007876  0.025990       0       0    0.942216   \n",
       "...        ...       ...       ...       ...     ...     ...         ...   \n",
       "1854  0.892545  0.057149  0.023222  0.027085       0       1    0.892545   \n",
       "1855  0.961319  0.018777  0.006115  0.013789       0       1    0.961319   \n",
       "1856  0.749548  0.114185  0.019516  0.116750       0       1    0.749548   \n",
       "1857  0.674184  0.204026  0.032775  0.089015       0       1    0.674184   \n",
       "1858  0.958773  0.018044  0.006239  0.016944       0       1    0.958773   \n",
       "1859  0.953622  0.022707  0.006370  0.017301       0       1    0.953622   \n",
       "1860  0.958606  0.021018  0.006260  0.014116       0       1    0.958606   \n",
       "1861  0.959270  0.020868  0.006102  0.013760       0       1    0.959270   \n",
       "1862  0.939205  0.033414  0.012164  0.015216       0       1    0.939205   \n",
       "1863  0.868050  0.052327  0.054751  0.024872       0       1    0.868050   \n",
       "1864  0.886798  0.036520  0.056507  0.020174       0       1    0.886798   \n",
       "1865  0.882143  0.040348  0.049786  0.027722       0       1    0.882143   \n",
       "1866  0.865635  0.041998  0.057360  0.035007       0       1    0.865635   \n",
       "1867  0.860071  0.045958  0.056441  0.037530       0       1    0.860071   \n",
       "1868  0.869419  0.041862  0.057165  0.031554       0       1    0.869419   \n",
       "1869  0.886257  0.036553  0.054973  0.022216       0       1    0.886257   \n",
       "1870  0.880457  0.040301  0.049728  0.029514       0       1    0.880457   \n",
       "1871  0.868302  0.044060  0.056153  0.031485       0       1    0.868302   \n",
       "1872  0.808277  0.072007  0.073849  0.045868       0       1    0.808277   \n",
       "1873  0.475748  0.156304  0.222501  0.145447       0       1    0.475748   \n",
       "1874  0.607726  0.134438  0.135215  0.122621       0       1    0.607726   \n",
       "1875  0.583026  0.137729  0.152405  0.126839       0       2    0.583026   \n",
       "1876  0.577112  0.126863  0.186181  0.109845       0       2    0.577112   \n",
       "1877  0.367023  0.150592  0.341523  0.140862       0       2    0.367023   \n",
       "1878  0.227425  0.159985  0.395985  0.216604       2       2    0.395985   \n",
       "1879  0.113856  0.113587  0.262781  0.509776       3       2    0.509776   \n",
       "1880  0.090292  0.092355  0.172258  0.645095       3       2    0.645095   \n",
       "1881  0.117120  0.123848  0.342103  0.416928       3       2    0.416928   \n",
       "1882  0.164007  0.146580  0.396678  0.292735       2       2    0.396678   \n",
       "1883  0.367793  0.140939  0.333788  0.157480       0       2    0.367793   \n",
       "\n",
       "      regression  \n",
       "0       0.983338  \n",
       "1       1.412557  \n",
       "2       1.052099  \n",
       "3       1.336556  \n",
       "4       0.989497  \n",
       "5       1.188042  \n",
       "6       1.297231  \n",
       "7       1.287593  \n",
       "8       1.330969  \n",
       "9       1.138692  \n",
       "10      1.137329  \n",
       "11      0.643973  \n",
       "12      0.888606  \n",
       "13      0.679383  \n",
       "14      0.665745  \n",
       "15      0.780477  \n",
       "16      0.674598  \n",
       "17      0.495376  \n",
       "18      0.623696  \n",
       "19      0.523978  \n",
       "20      0.708772  \n",
       "21      0.136467  \n",
       "22      0.380688  \n",
       "23      0.110057  \n",
       "24      0.084551  \n",
       "25      0.148935  \n",
       "26      0.151136  \n",
       "27      0.125364  \n",
       "28      0.116972  \n",
       "29      0.117640  \n",
       "...          ...  \n",
       "1854    0.184847  \n",
       "1855    0.072374  \n",
       "1856    0.503469  \n",
       "1857    0.536621  \n",
       "1858    0.081354  \n",
       "1859    0.087351  \n",
       "1860    0.075886  \n",
       "1861    0.074352  \n",
       "1862    0.103391  \n",
       "1863    0.236445  \n",
       "1864    0.210058  \n",
       "1865    0.223088  \n",
       "1866    0.261738  \n",
       "1867    0.271430  \n",
       "1868    0.250854  \n",
       "1869    0.213148  \n",
       "1870    0.228300  \n",
       "1871    0.250821  \n",
       "1872    0.357307  \n",
       "1873    1.037648  \n",
       "1874    0.772732  \n",
       "1875    0.823057  \n",
       "1876    0.828758  \n",
       "1877    1.256224  \n",
       "1878    1.601767  \n",
       "1879    2.168476  \n",
       "1880    2.372156  \n",
       "1881    2.058840  \n",
       "1882    1.818140  \n",
       "1883    1.280956  \n",
       "\n",
       "[1884 rows x 8 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(columns=['proba_0', 'proba_1', 'proba_2', 'proba_3'])\n",
    "\n",
    "df['y_pred'] = xgb_predictor.predict(fdset.X_test)\n",
    "df['y_true'] = fdset.y_test\n",
    "\n",
    "probas = xgb_predictor.predict_proba(fdset.X_test)\n",
    "\n",
    "df['confidence'] = np.max(probas, axis=1)\n",
    "df['regression'] = np.matmul(probas, np.arange(4))\n",
    "df[['proba_0', 'proba_1', 'proba_2', 'proba_3']] = probas\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try Power Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'fdset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-3f982eb51560>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mdel\u001b[0m \u001b[0mfdset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m fdset2 = FaciesDataset([\"205-21b-3\", \"204-24a-6\", \"204-20-6a\"],\n\u001b[1;32m      4\u001b[0m                     \u001b[0mtest_wells\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"204-19-6\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                     \u001b[0mfeatures\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"pseudoGR\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'fdset' is not defined"
     ]
    }
   ],
   "source": [
    "del fdset\n",
    "\n",
    "fdset2 = FaciesDataset([\"205-21b-3\", \"204-24a-6\", \"204-20-6a\"],\n",
    "                    test_wells=[\"204-19-6\"],\n",
    "                    features=[\"pseudoGR\"],\n",
    "                    pseudoGR_args={'scale_mode': 'power'},\n",
    "                    label_resolution=32*4)\n",
    "\n",
    "fdset2.load_or_generate_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_xgb_model2(model_config):\n",
    "    xgb_predictor = FeaturePredictor(fdset2, \n",
    "                                     model_args=model_config, \n",
    "                                     feature_model_args=feat_model_args)\n",
    "    test_acc = xgb_predictor.fit(fdset2, verbose=False)\n",
    "    y_pred = xgb_predictor.predict(fdset2.X_test)\n",
    "    print('F1 score:', f1_score(fdset2.y_test, y_pred, average='macro'))\n",
    "    return log_loss(fdset2.y_test, xgb_predictor.predict_proba(fdset2.X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'XGB_SEARCH_SPACE' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-d6c5e6d4e0f2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m best_params = hyperopt.fmin(\n\u001b[1;32m      2\u001b[0m     \u001b[0mfn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_xgb_model2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mspace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mXGB_SEARCH_SPACE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0malgo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhyperopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuggest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mmax_evals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'XGB_SEARCH_SPACE' is not defined"
     ]
    }
   ],
   "source": [
    "best_params = hyperopt.fmin(\n",
    "    fn=train_xgb_model2,\n",
    "    space=XGB_SEARCH_SPACE,\n",
    "    algo=hyperopt.rand.suggest,\n",
    "    max_evals=50\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for feature:  pseudoGR\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "           sandstone       0.84      0.44      0.58       234\n",
      "clay-prone sandstone       0.00      0.00      0.00        79\n",
      "      sandy mudstone       0.17      0.40      0.24        72\n",
      "            mudstone       0.43      0.84      0.56        88\n",
      "\n",
      "           micro avg       0.44      0.44      0.44       473\n",
      "           macro avg       0.36      0.42      0.35       473\n",
      "        weighted avg       0.52      0.44      0.43       473\n",
      "\n",
      "Total accuracy Score :  0.4376321353065539\n",
      "Confusion Matrix: \n",
      " [[104   0  86  44]\n",
      " [ 17   0  48  14]\n",
      " [  1   0  29  42]\n",
      " [  2   2  10  74]]\n",
      "('var', 0.23149236)\n",
      "('IF_1', 0.17626321)\n",
      "('b', 0.10144927)\n",
      "('median', 0.08382295)\n",
      "('IF_0', 0.08343126)\n",
      "('m3', 0.079905994)\n",
      "('m1', 0.07716412)\n",
      "('gmean', 0.07363886)\n",
      "('mean', 0.05757932)\n",
      "('m2', 0.035252646)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None, None, None, None, None, None, None, None]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {**XGB_SEARCH_SPACE, \n",
    "          **best_params, \n",
    "          **{'max_depth': int(best_params['max_depth']), 'n_estimators': int(best_params['n_estimators'])}}\n",
    "\n",
    "xgb_predictor = FeaturePredictor(fdset2, model_args=params, feature_model_args=feat_model_args)\n",
    "xgb_predictor.fit(fdset2, verbose=True)\n",
    "\n",
    "imps = list(zip(feat_names, xgb_predictor.model.feature_importances_))\n",
    "imps.sort(key = lambda p: p[1])\n",
    "[print(pair) for pair in imps[::-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from coremdlr.models_utils import make_confusion_fig\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm = confusion_matrix(df['y_true'].values, df['y_pred'].values)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f3460616d30>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "make_confusion_fig(cm, fdset.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('TPM_test.csv', sep='\\t', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
